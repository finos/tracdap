#  Copyright 2020 Accenture Global Solutions Limited
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

from __future__ import annotations

import itertools as it
import re
import typing as tp
import pathlib
import logging

import google.protobuf.descriptor_pb2 as pb_desc  # noqa
import google.protobuf.compiler.plugin_pb2 as pb_plugin  # noqa


class LocationContext:

    def __init__(self, src_locations: tp.List[pb_desc.SourceCodeInfo.Location],
                 src_loc_code: int, src_loc_index: int, indent: int):

        self.src_locations = src_locations
        self.src_loc_code = src_loc_code
        self.src_loc_index = src_loc_index
        self.indent = indent

    def for_index(self, index: int) -> LocationContext:

        return LocationContext(self.src_locations, self.src_loc_code, index, self.indent)


class ECodeGeneration(RuntimeError):

    """
    An error occurred in the code generation process
    (This is not part of the ETrac hierarchy as it is a build-time error)
    """

    pass


class TracGenerator:
    
    _FieldType = pb_desc.FieldDescriptorProto.Type

    PROTO_TYPE_MAPPING = dict({

        _FieldType.TYPE_DOUBLE: float,
        _FieldType.TYPE_FLOAT: float,
        _FieldType.TYPE_INT64: int,
        _FieldType.TYPE_UINT64: int,
        _FieldType.TYPE_INT32: int,
        _FieldType.TYPE_FIXED64: int,
        _FieldType.TYPE_FIXED32: int,
        _FieldType.TYPE_BOOL: bool,
        _FieldType.TYPE_STRING: str,
        
        # Group type is deprecated and not supported in proto3
        # _FieldType.TYPE_GROUP
        
        # Do not include a mapping for message type, it will be handle specially
        # _FieldType.TYPE_MESSAGE

        _FieldType.TYPE_BYTES: bytes,  # TODO: Use bytearray?
        
        _FieldType.TYPE_UINT32: int,

        # Do not include a mapping for enum type, it will be handle specially
        # _FieldType.TYPE_ENUM

        _FieldType.TYPE_SFIXED32: int,
        _FieldType.TYPE_SFIXED64: int,
        _FieldType.TYPE_SINT32: int,
        _FieldType.TYPE_SINT64: int
    })

    INDENT_TEMPLATE = ' ' * 4

    PACKAGE_IMPORT_TEMPLATE = 'from .{MODULE_NAME} import {SYMBOL}\n'

    FILE_TEMPLATE = (
        '# Code generated by TRAC\n'
        '\n'
        '{IMPORT_STATEMENTS}'
        '\n\n'
        '{ENUMS_CODE}'
        '\n'
        '{MESSAGES_CODE}')

    DATA_CLASS_TEMPLATE = (
        '{INDENT}@_dc.dataclass\n'
        '{INDENT}class {CLASS_NAME}:\n'
        '\n'
        '{DOC_COMMENT}'
        '{NESTED_ENUMS}'
        '{NESTED_CLASSES}'
        '{DATA_MEMBERS}')

    DATA_MEMBER_TEMPLATE = (
        '{INDENT}{MEMBER_NAME}: {MEMBER_TYPE} = {MEMBER_DEFAULT}'
        '\n\n'
        '{DOC_COMMENT}')

    ENUM_TEMPLATE = (
        '{INDENT}class {CLASS_NAME}(_enum.Enum):'
        '\n\n'
        '{DOC_COMMENT}'
        '{ENUM_VALUES}')

    ENUM_VALUE_TEMPLATE = (
        '{INDENT}{ENUM_VALUE_NAME} = {ENUM_VALUE_NUMBER}, {QUOTED_COMMENT}\n\n')

    PASS_TEMPLATE = (
        '{INDENT}pass\n\n')

    COMMENT_SINGLE_LINE = (
        '{INDENT}"""{COMMENT}"""\n\n')

    COMMENT_MULTI_LINE = (
        '{INDENT}"""\n'
        '{COMMENT}\n'
        '{INDENT}"""\n\n')

    ENUM_COMMENT_SINGLE_LINE = \
        '"""{COMMENT}"""'

    ENUM_COMMENT_MULTI_LINE = \
        '"""{COMMENT}\n' \
        '{INDENT}"""'

    def __init__(self):

        logging.basicConfig(level=logging.DEBUG)
        self._log = logging.getLogger(TracGenerator.__name__)

        self._enum_type_field = self.get_field_number(pb_desc.FileDescriptorProto, "enum_type")
        self._message_type_field = self.get_field_number(pb_desc.FileDescriptorProto, "message_type")
        self._message_field_field = self.get_field_number(pb_desc.DescriptorProto, "field")
        self._enum_value_field = self.get_field_number(pb_desc.EnumDescriptorProto, "value")

        self._known_messages: tp.Dict[str, pb_desc.DescriptorProto] = {}
        self._known_enums: tp.Dict[str, pb_desc.EnumDescriptorProto] = {}

    def generate_package(self, package: str, files: tp.List[pb_desc.FileDescriptorProto]) \
            -> tp.List[pb_plugin.CodeGeneratorResponse.File]:

        self._log.info(f" [ PKG  ] -> {package} ({len(files)} proto files)")

        output_files = []

        # Use the protobuf package as the Python package
        package_path = pathlib.Path(*package.split("."))
        package_imports = ""

        for file_descriptor in files:

            # Run the generator to produce code for the Python module
            src_locations = file_descriptor.source_code_info.location
            file_code = self.generate_file(src_locations, 0, file_descriptor)

            # Find the module name inside the package - this is the stem of the .proto file
            file_path = pathlib.PurePath(file_descriptor.name)
            file_stem = file_path.stem

            # Create a generator response for the module
            file_response = pb_plugin.CodeGeneratorResponse.File()
            file_response.content = file_code

            # File name is formed from the python package and the module name (.proto file stem)
            file_response.name = str(package_path.joinpath(file_stem + ".py"))

            output_files.append(file_response)

            # Generate import statements to include in the package-level __init__ file
            package_imports += self.generate_package_imports(file_descriptor)

        # Add an extra generator response file for the package-level __init__ file
        package_init_file = pb_plugin.CodeGeneratorResponse.File()
        package_init_file.name = str(package_path.joinpath("__init__.py"))
        package_init_file.content = package_imports

        output_files.append(package_init_file)

        return output_files

    def generate_package_imports(self, descriptor: pb_desc.FileDescriptorProto) -> str:

        file_path = pathlib.Path(descriptor.name)
        module_name = file_path.stem

        imports = ""

        if len(descriptor.enum_type) > 0 or len(descriptor.message_type) > 0:
            imports += "\n"

        for enum_type in descriptor.enum_type:
            imports += self.PACKAGE_IMPORT_TEMPLATE.format(
                MODULE_NAME=module_name,
                SYMBOL=enum_type.name)

        for message_type in descriptor.message_type:
            imports += self.PACKAGE_IMPORT_TEMPLATE.format(
                MODULE_NAME=module_name,
                SYMBOL=message_type.name)

        return imports

    def generate_file(self, src_loc, indent: int, descriptor: pb_desc.FileDescriptorProto) -> str:

        self._log.info(f" [ FILE ] -> {descriptor.name}")

        imports = [
            "from __future__ import annotations\n",
            "import typing as _tp\n",
            "import dataclasses as _dc\n"]

        if len(descriptor.enum_type) > 0:
            imports.append("import enum as _enum\n")

        # Generate imports
        for import_proto in descriptor.dependency:
            if import_proto.startswith("trac/metadata/"):
                import_module = import_proto \
                    .replace("trac/metadata/", "") \
                    .replace("/", ".") \
                    .replace(".proto", "")
                imports.append("from .{} import *  # noqa\n".format(import_module))

        # Record known types
        self._known_enums.update({t.name: t for t in descriptor.enum_type})
        self._known_messages.update({t.name: t for t in descriptor.message_type})

        # Generate enums
        enum_ctx = self.index_sub_ctx(src_loc, self._enum_type_field, indent)
        enums = list(it.starmap(self.generate_enum, zip(enum_ctx, descriptor.enum_type)))

        # Generate data classes
        dataclass_ctx = self.index_sub_ctx(src_loc, self._message_type_field, indent)
        dataclasses = list(it.starmap(self.generate_data_class, zip(dataclass_ctx, descriptor.message_type)))

        # Populate the template
        code = self.FILE_TEMPLATE \
            .replace("{INDENT}", self.INDENT_TEMPLATE * indent) \
            .replace("{IMPORT_STATEMENTS}", "".join(imports)) \
            .replace("{ENUMS_CODE}", "\n".join(enums)) \
            .replace("{MESSAGES_CODE}", "\n".join(dataclasses))

        # Strip multiple newlines from the end of the file
        while code.endswith("\n\n"):
            code = code[:-1]

        return code

    def generate_data_class(
            self, ctx: LocationContext,
            descriptor: pb_desc.DescriptorProto,
            message_scope: str = None) -> str:

        log_indent = self.INDENT_TEMPLATE * (ctx.indent + 1)
        self._log.info(f" [ MSG  ] {log_indent}-> {descriptor.name}")

        # Source location and scope for this message
        filtered_loc = self.filter_src_location(ctx.src_locations, ctx.src_loc_code, ctx.src_loc_index)
        nested_scope = descriptor.name if message_scope is None else f"{message_scope}.{descriptor.name}"

        # Generate nested enums
        nested_enums_ctx = self.index_sub_ctx(filtered_loc, self._enum_type_field, ctx.indent + 1)
        nested_enums = []

        for enum_ctx, enum_desc in zip(nested_enums_ctx, descriptor.enum_type):

            nested_enum_name = f"{nested_scope}.{enum_desc.name}"
            nested_enum = self.generate_enum(enum_ctx, enum_desc, nested_scope)
            nested_enums.append(nested_enum)
            self._known_enums[nested_enum_name] = enum_desc

        # Generate nested message classes
        nested_types_ctx = self.index_sub_ctx(filtered_loc, self._message_type_field, ctx.indent + 1)
        nested_types = []

        for sub_ctx, sub_desc in zip(nested_types_ctx, descriptor.nested_type):

            if not sub_desc.options.map_entry:
                nested_type_name = f"{nested_scope}.{sub_desc.name}"
                nested_type = self.generate_data_class(sub_ctx, sub_desc, nested_scope)
                nested_types.append(nested_type)
                self._known_messages[nested_type_name] = sub_desc

        # Generate data members - these may reference known message and enum types
        data_members_ctx = LocationContext(filtered_loc, ctx.src_loc_code, ctx.src_loc_index, ctx.indent + 1)
        data_members = self.generate_data_members(data_members_ctx, descriptor)

        # Generate comments
        raw_comment = self.comment_for_current_location(filtered_loc)
        doc_comment = self.format_doc_comment(ctx, raw_comment, next_indent=True)

        return self.DATA_CLASS_TEMPLATE \
            .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
            .replace("{NEXT_INDENT}", self.INDENT_TEMPLATE * (ctx.indent + 1)) \
            .replace("{CLASS_NAME}", descriptor.name) \
            .replace("{DOC_COMMENT}", doc_comment) \
            .replace("{NESTED_ENUMS}", "".join(nested_enums)) \
            .replace("{NESTED_CLASSES}", "".join(nested_types)) \
            .replace("{DATA_MEMBERS}", data_members)

    def generate_data_members(self, ctx: LocationContext, descriptor: pb_desc.DescriptorProto) -> str:

        # Generate a pass statement if the class has no members
        if not descriptor.field:
            return self.PASS_TEMPLATE.replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent)

        members_ctx = self.index_sub_ctx(
            ctx.src_locations,
            self._message_field_field,
            ctx.indent)

        members = list(map(lambda f: self.generate_data_member(
            next(members_ctx), descriptor, f),
            descriptor.field))

        return "".join(members)

    def generate_data_member(
            self, ctx: LocationContext,
            message: pb_desc.DescriptorProto,
            field: pb_desc.FieldDescriptorProto) \
            -> str:

        filtered_loc = self.filter_src_location(ctx.src_locations, ctx.src_loc_code, ctx.src_loc_index)

        field_type = self.python_field_type(field, message)
        field_default = self.python_default_value(field, message)

        raw_comment = self.comment_for_current_location(filtered_loc)
        doc_comment = self.format_doc_comment(ctx, raw_comment)

        return self.DATA_MEMBER_TEMPLATE \
            .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
            .replace("{MEMBER_NAME}", field.name) \
            .replace("{MEMBER_TYPE}", field_type) \
            .replace("{MEMBER_DEFAULT}", field_default) \
            .replace("{DOC_COMMENT}", doc_comment)

    def generate_enum(
            self, ctx: LocationContext,
            descriptor: pb_desc.EnumDescriptorProto,
            enum_scope: str = None) \
            -> str:

        log_indent = self.INDENT_TEMPLATE * (ctx.indent + 1)
        self._log.info(f" [ ENUM ] {log_indent}-> {descriptor.name}")

        # There is a problem constructing Python data classes for nested enums
        # The default initializer is not available until the outer class is declared
        # A solution is to create the enum at file scope with a _ prefix and alias it to create the nested version
        # https://stackoverflow.com/a/54489183
        if enum_scope:
            scoped_name = f"{enum_scope}.{descriptor.name}"
            err = f" [ ENUM ] {scoped_name}: Nested enums not currently supported"
            self._log.error(err)
            raise ECodeGeneration(err)

        filtered_loc = self.filter_src_location(ctx.src_locations, ctx.src_loc_code, ctx.src_loc_index)

        # Generate a pass statement if the enum has no members (protoc should prevent this anyway)
        if not descriptor.value:
            return self.PASS_TEMPLATE.replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent)

        # Generate enum values
        values_ctx = self.index_sub_ctx(
            filtered_loc,
            self._enum_value_field,
            ctx.indent + 1)

        values = list(map(lambda ev: self.generate_enum_value(
            next(values_ctx), ev),
            descriptor.value))

        # Generate top level comments for the type
        raw_comment = self.comment_for_current_location(filtered_loc)
        doc_comment = self.format_doc_comment(ctx, raw_comment, next_indent=True)

        # Populate the template
        return self.ENUM_TEMPLATE \
            .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
            .replace("{NEXT_INDENT}", self.INDENT_TEMPLATE * (ctx.indent + 1)) \
            .replace("{DOC_COMMENT}", doc_comment) \
            .replace("{CLASS_NAME}", descriptor.name) \
            .replace("{ENUM_VALUES}", "".join(values))

    def generate_enum_value(self, ctx: LocationContext, descriptor: pb_desc.EnumValueDescriptorProto) -> str:

        filtered_loc = self.filter_src_location(ctx.src_locations, ctx.src_loc_code, ctx.src_loc_index)

        # Comments from current code location
        raw_comment = self.comment_for_current_location(filtered_loc)
        formatted_comment = self.format_enum_comment(ctx, raw_comment)

        # Populate the template
        return self.ENUM_VALUE_TEMPLATE \
            .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
            .replace("{QUOTED_COMMENT}", formatted_comment) \
            .replace("{ENUM_VALUE_NAME}", descriptor.name) \
            .replace("{ENUM_VALUE_NUMBER}", str(descriptor.number))

    # Python type hints

    def python_field_type(self, field: pb_desc.FieldDescriptorProto, message: pb_desc.DescriptorProto):

        base_type = self.python_base_type(field)

        # Repeated fields are either lists or maps - these need special handling
        if field.label == field.Label.LABEL_REPEATED:

            # Look to see if the base type is a nested type defined in the same message as the field
            nested_type = next(filter(
                lambda nt: base_type == f"{message.name}.{nt.name}",
                message.nested_type),
                None)

            # If a nested type is found to be a map entry type, then generate a dict
            if nested_type is not None and nested_type.options.map_entry:

                key_type = self.python_base_type(nested_type.field[0])
                value_type = self.python_base_type(nested_type.field[1])
                return f"_tp.Dict[{key_type}, {value_type}]"

            # Otherwise repeated fields are generated as lists
            else:
                return f"_tp.List[{base_type}]"

        # Fields in a oneof group are always optional
        # If no oneof group is set, oneof_index will have default value of 0
        # To check if this field is really set, use HasField()
        elif field.HasField('oneof_index'):
            return f"_tp.Optional[{base_type}]"

        # Message fields are always optional and can be set to null
        elif field.type == field.Type.TYPE_MESSAGE:
            return f"_tp.Optional[{base_type}]"

        # Enum fields are always set to a value (the enum' zero value)
        elif field.type == field.Type.TYPE_ENUM:
            return base_type

        # Assume everything else is a primitive
        else:
            return base_type

    def python_base_type(self, field: pb_desc.FieldDescriptorProto):

        # Messages (classes) and enums use the type name declared in the field
        if field.type == field.Type.TYPE_MESSAGE or field.type == field.Type.TYPE_ENUM:

            type_name = field.type_name
            relative_name = type_name.replace(".trac.metadata.", "", 1)

            # We are using deferred annotations, with from __future__ import annotations
            # Type names no longer need to be quoted!

            return relative_name

        # For built in types, use a static mapping of proto type names
        if field.type in self.PROTO_TYPE_MAPPING:

            return self.PROTO_TYPE_MAPPING[field.type].__name__

        # Any unrecognised type is an error
        raise ECodeGeneration(
            "Unknown type in protobuf field descriptor: field = {}, type code = {}"
            .format(field.name, field.type))

    # Python defaults

    def python_default_value(self, field: pb_desc.FieldDescriptorProto, message: pb_desc.DescriptorProto):

        base_type = self.python_base_type(field)

        # Repeated fields are either lists or maps - these need special handling
        if field.label == field.Label.LABEL_REPEATED:

            # Look to see if the base type is a nested type defined in the same message as the field
            nested_type = next(filter(
                lambda nt: base_type == f"{message.name}.{nt.name}",
                message.nested_type),
                None)

            # Use _dc.field to initialise dicts and lists
            if nested_type is not None and nested_type.options.map_entry:
                return "_dc.field(default_factory=dict)"
            else:
                return "_dc.field(default_factory=list)"

        # Fields in a oneof group are always optional
        elif field.HasField('oneof_index'):
            return "None"

        # Message fields are always optional and can be set to null
        elif field.type == field.Type.TYPE_MESSAGE:
            return "None"

        # Enum fields are always set to a value (the enum' zero value)
        elif field.type == field.Type.TYPE_ENUM:
            enum_type = self._known_enums[base_type]
            return f"{enum_type.name}.{enum_type.value[0].name}"

        # Assume everything else is a primitive
        else:
            return "None"

    # Comments

    def comment_for_current_location(self, locations) -> tp.Optional[str]:

        # Comments from current code location
        current_loc = self.current_location(locations)

        if current_loc is not None:
            return current_loc.leading_comments
        else:
            return None

    def format_doc_comment(
            self, ctx: LocationContext,
            comment: tp.Optional[str],
            next_indent: bool = False) \
            -> tp.Optional[str]:

        translated_comment = self.translate_comment_from_proto(ctx, comment, next_indent)
        indent = ctx.indent + 1 if next_indent else ctx.indent

        if translated_comment is None or translated_comment.strip() == "":
            return ""

        if "\n" in translated_comment.strip():

            return self.COMMENT_MULTI_LINE \
                .replace("{INDENT}", self.INDENT_TEMPLATE * indent) \
                .replace("{COMMENT}", translated_comment)

        else:

            return self.COMMENT_SINGLE_LINE \
                .replace("{INDENT}", self.INDENT_TEMPLATE * indent) \
                .replace("{COMMENT}", translated_comment.strip())

    def format_enum_comment(self, ctx: LocationContext, comment: tp.Optional[str]) -> tp.Optional[str]:

        translated_comment = self.translate_comment_from_proto(ctx, comment)
        translated_comment = translated_comment.lstrip()  # Enum comments should start immediately after the quotes

        if translated_comment.strip() == "":
            return ''

        elif "\n" not in translated_comment.strip():
            return self.ENUM_COMMENT_SINGLE_LINE \
                .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
                .replace("{COMMENT}", translated_comment.strip())

        else:
            return self.ENUM_COMMENT_MULTI_LINE \
                .replace("{INDENT}", self.INDENT_TEMPLATE * ctx.indent) \
                .replace("{COMMENT}", translated_comment)

    def translate_comment_from_proto(
            self, ctx: LocationContext,
            comment: tp.Optional[str],
            next_indent: bool = False) \
            -> tp.Optional[str]:

        if comment is None:
            return ""

        indent = ctx.indent + 1 if next_indent else ctx.indent

        translated_comment = re.sub("^(\\*\n)|/", "", comment, count=1)
        translated_comment = re.sub("\n$", "", translated_comment)
        translated_comment = re.sub("^ ?", self.INDENT_TEMPLATE * indent, translated_comment)
        translated_comment = re.sub("\\n ?", "\n" + self.INDENT_TEMPLATE * indent, translated_comment)

        if translated_comment.strip() == "":
            return ""

        return translated_comment

    # Source location filtering

    @staticmethod
    def filter_src_location(locations, loc_type, loc_index):

        def relative_path(loc: pb_desc.SourceCodeInfo.Location):

            return pb_desc.SourceCodeInfo.Location(
                path=loc.path[2:], span=loc.span,
                leading_comments=loc.leading_comments,
                trailing_comments=loc.trailing_comments,
                leading_detached_comments=loc.leading_detached_comments)

        filtered = filter(lambda l: len(l.path) >= 2 and l.path[0] == loc_type and l.path[1] == loc_index, locations)
        return list(map(relative_path, filtered))

    @staticmethod
    def current_location(locations) -> pb_desc.SourceCodeInfo.Location:

        return next(filter(lambda l: len(l.path) == 0, locations), None)

    @staticmethod
    def index_sub_ctx(src_locations, field_number, indent):

        base_ctx = LocationContext(src_locations, field_number, 0, indent)
        return iter(map(base_ctx.for_index, it.count(0)))

    @staticmethod
    def indent_sub_ctx(ctx: LocationContext, indent: int):

        return LocationContext(ctx.src_locations, ctx.src_loc_code, ctx.src_loc_index, ctx.indent + indent)

    # Helpers

    @staticmethod
    def get_field_number(message_descriptor, field_name: str):

        field_descriptor = next(filter(
            lambda f: f.name == field_name,
            message_descriptor.DESCRIPTOR.fields), None)

        if field_descriptor is None:

            raise ECodeGeneration(
                "Field {} not found in type {}"
                .format(field_name, message_descriptor.DESCRIPTOR.name))

        return field_descriptor.number
