name: Build and Test

# Run the main build and test for all branch pushes and pull requests, do not repeat the build for tags
on:
  push:
    branches:
      - '**'
  pull_request:


env:
  JAVA_DISTRIBUTION: zulu
  NODE_VERSION: 14.x


jobs:

  platform_build:

    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      matrix:
        JAVA_VERSION:
          - 11
          - 17

    steps:

    # fetch-depth = 0 is needed to get tags for version info
    - name: Checkout
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: Set up Java
      uses: actions/setup-java@v3
      with:
        distribution: ${{ env.JAVA_DISTRIBUTION }}
        java-version: ${{ matrix.JAVA_VERSION }}

        # Turn on Gradle dependency caching
        cache: gradle

    - name: Build
      run: ./gradlew classes testClasses

    - name: Unit tests
      run: ./gradlew test

    # If the tests fail, make the output available for download
    - name: Store failed test results
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: junit-test-results
        path: build/modules/*/reports/**
        retention-days: 7


  python_runtime:

    # Testing targets for the Python model runtime
    # Include the latest stable release (3.9)
    # Oldest supported version is 3.6, this is required by Pandas 1.0
    # (also note Python 3.5 is EOL, final release 3.5.10 was in September 2020)
    # Do not include 2.7 - that ship has sailed!
    strategy:

      # Try to finish all jobs - it can be helpful to see if some succeed and others fail
      fail-fast: false

      matrix:
        environment:

          # Latest supported versions on all 3 major platforms
          - { ENV_NAME: "Windows, 3.11, Pandas 2.1, PySpark 3.3",
              PLATFORM: 'windows-latest',
              PYTHON_VERSION: "3.11",
              PANDAS_VERSION: ">= 2.1.0, < 2.2.0",
              PYSPARK_VERSION: ">= 3.3.0, < 3.4.0",
              PYPANDOC: false }

          - { ENV_NAME: "macOS, 3.11, Pandas 2.1, PySpark 3.3",
              PLATFORM: 'macos-latest',
              PYTHON_VERSION: "3.11",
              PANDAS_VERSION: ">= 2.1.0, < 2.2.0",
              PYSPARK_VERSION: ">= 3.3.0, < 3.4.0",
              PYPANDOC: false }

          - { ENV_NAME: "Linux, 3.11, Pandas 2.1, PySpark 3.3",
              PLATFORM: 'ubuntu-latest',
              PYTHON_VERSION: "3.11",
              PANDAS_VERSION: ">= 2.1.0, < 2.2.0",
              PYSPARK_VERSION: ">= 3.3.0, < 3.4.0",
              PYPANDOC: false }

          # Intermediate supported versions
          - { ENV_NAME: "Linux, 3.9, Pandas 2.0, PySpark 3.2",
              PLATFORM: 'ubuntu-latest',
              PYTHON_VERSION: "3.10",
              PANDAS_VERSION: "== 2.0.0",
              PYSPARK_VERSION: ">= 3.2.0, < 3.3.0",
              PYPANDOC: false }

          - { ENV_NAME: "Linux, 3.9, Pandas 1.5, PySpark 3.0",
              PLATFORM: 'ubuntu-latest',
              PYTHON_VERSION: "3.9",
              PANDAS_VERSION: ">= 1.5.0, < 1.6.0",
              PYSPARK_VERSION: ">= 3.0.0, < 3.1.0",
              PYPANDOC: false }

          # Oldest supported versions, force testing against .0 for Pandas and PySpark
          # If those don't work due to bugs, we need to update README for the supported versions
          - { ENV_NAME: "Linux, 3.7, Pandas 1.2, PySpark 2.4",
              PLATFORM: 'ubuntu-latest',
              PYTHON_VERSION: "3.7",
              PANDAS_VERSION: "== 1.2.0",
              PYSPARK_VERSION: "== 2.4.0",
              PYPANDOC: true }

    runs-on: ${{ matrix.environment.PLATFORM }}
    timeout-minutes: 20

    steps:

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.environment.PYTHON_VERSION }}

      - name: PIP Upgrade
        run: python -m pip install --upgrade pip

      # fetch-depth = 0 is needed to get tags for version info
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      #  For PySpark, dependencies removed from build since Spark is not supported in 0.5 series
      #  PyPanDoc was required for Spark 2.x series, however minimum supported Spark version is now 3.0
      #  pip install "pypandoc <1.8"
      #  pip install "pyspark ${{ matrix.environment.PYSPARK_VERSION }}"

      - name: Install dependencies
        run: |
          pip install "pandas ${{ matrix.environment.PANDAS_VERSION }}"
          cd tracdap-runtime/python
          pip install -r requirements.txt

      - name: Protoc code generation
        run: python tracdap-runtime/python/build_runtime.py --target codegen

      - name: Unit tests
        run: python tracdap-runtime/python/build_runtime.py --target test

      - name: Python example models
        run: python tracdap-runtime/python/build_runtime.py --target examples


  web_api:

    runs-on: ubuntu-latest

    steps:

    # fetch-depth = 0 is needed to get tags for version info
    - name: Checkout
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: npm
        cache-dependency-path: tracdap-api/packages/web/package-lock.json

    - name: Install dependencies
      run: |
        cd tracdap-api/packages/web
        npm install

    - name: Build API
      run: |
        cd tracdap-api/packages/web
        npm run buildApi


  documentation:

    runs-on: ubuntu-latest

    steps:

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: PIP Upgrade
        run: python -m pip install --upgrade pip

      # fetch-depth = 0 is needed to get tags for version info
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Install dependencies for build tools
        run: |
          cd dev/
          pip install -r requirements.txt

      - name: Run all docgen targets
        run: |
          cd dev/
          python docgen/docgen-ctrl.py all
